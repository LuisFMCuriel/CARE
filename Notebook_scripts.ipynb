{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Test.ipynb","provenance":[{"file_id":"1I2tHpSpwZo7hDmlVV0nbTBKrwXv1Zg42","timestamp":1589361285138}],"collapsed_sections":[],"authorship_tag":"ABX9TyMiSM3Tl2g/jzLqYHvINkjJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"l363Iz75UAqb","colab_type":"code","outputId":"cc087884-2d02-4d77-d39e-dd17f2578fbd","executionInfo":{"status":"error","timestamp":1589809874624,"user_tz":300,"elapsed":1301020,"user":{"displayName":"Luis Felipe Morales","photoUrl":"","userId":"10552061088031501211"}},"cellView":"form","colab":{"base_uri":"https://localhost:8080/","height":655}},"source":["#Install and import dependencies\n","#Here, we install libraries which are not already included in Colab.\n","#!pip install tifffile # contains tools to operate tiff-files\n","#!pip install csbdeep  # contains tools for restoration of fluorescence microcopy images (Content-aware Image Restoration, CARE). It uses Keras and Tensorflow.\n","#!pip install memory_profiler\n","!pip install memory_profiler\n","%load_ext memory_profiler\n","%tensorflow_version 1.x\n","\n","import tensorflow as tf\n","if tf.test.gpu_device_name()=='':\n","  print('You do not have GPU access.') \n","  print('Did you change your runtime ?') \n","  print('If the runtime settings are correct then Google did not allocate GPU to your session')\n","  print('Expect slow performance. To access GPU try reconnecting later')\n","\n","else:\n","  print('You have GPU access')\n","\n","from tensorflow.python.client import device_lib \n","device_lib.list_local_devices()\n","\n","#@markdown ##Play the cell to train your neural network\n","#@markdown ###Remember to give your credentials, don't worry I will wait\n","#@markdown ## ¯ \\ _ (ツ) _ / ¯\n","from __future__ import print_function, unicode_literals, absolute_import, division\n","from google.colab import drive\n","drive.mount('/content/gdrive') \n","#Select the path to the script\n","Path_Train_script = \"/content/gdrive/My Drive/Colab Notebooks\" #@param {type:\"string\"}\n","import sys \n","import os\n","sys.path.append(os.path.abspath(Path_Train_script))\n","import Training\n","\n","#@markdown ###Path to training images:\n","\n","# low SNR images\n","# low = \"/content/gdrive/My Drive/Work/manuscript/Ongoing Projects/Zero-Cost Deep-Learning to Enhance Microscopy/Notebooks to be tested/Training datasets/CARE (2D)/Training - Low SNR images\" #@param {type:\"string\"}\n","Training_source = \"/content/gdrive/My Drive/cloud_colab/CARE (2D)/Train_300img/Low\" #@param {type:\"string\"}\n","\n","# Ground truth images\n","# GT = \"/content/gdrive/My Drive/Work/manuscript/Ongoing Projects/Zero-Cost Deep-Learning to Enhance Microscopy/Notebooks to be tested/Training datasets/CARE (2D)/Training - High SNR images\" #@param {type:\"string\"}\n","Training_target = \"/content/gdrive/My Drive/cloud_colab/CARE (2D)/Train_300img/High\" #@param {type:\"string\"}\n","\n","# model name and path\n","#@markdown ###Name of the model and path to model folder:\n","model_name = \"DELETE_ME\" #@param {type:\"string\"}\n","model_path = \"/content/gdrive/My Drive/cloud_colab/CARE_WORMS1/models\" #@param {type:\"string\"}\n","\n","#@markdown ####Use one image of the training set for visual assessment of the training:\n","Visual_validation_after_training = True #@param {type:\"boolean\"}\n","\n","\n","# other parameters for training.\n","#@markdown ###Training Parameters\n","#@markdown Number of epochs:\n","\n","number_of_epochs =  1#@param {type:\"number\"}\n","\n","#@markdown Patch size (pixels) and number\n","patch_size =  64#@param {type:\"number\"} # in pixels\n","\n","number_of_patches =   10#@param {type:\"number\"}\n","\n","\n","#@markdown ###Advanced Parameters\n","\n","Use_Default_Advanced_Parameters = True #@param {type:\"boolean\"}\n","#@markdown ###If not, please input:\n","\n","number_of_steps =  300 #@param {type:\"number\"}\n","batch_size =  32#@param {type:\"number\"}\n","percentage_validation =  15 #@param {type:\"number\"}\n","\n","\n","Training.train(Training_source, Training_target,\n","                model_name,\n","                model_path,\n","                Visual_validation_after_training,\n","                number_of_epochs,\n","                patch_size,\n","                number_of_patches,\n","                Use_Default_Advanced_Parameters,\n","                number_of_steps,\n","                batch_size,\n","                percentage_validation)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: memory_profiler in /usr/local/lib/python3.6/dist-packages (0.57.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from memory_profiler) (5.4.8)\n","The memory_profiler extension is already loaded. To reload it, use:\n","  %reload_ext memory_profiler\n","You have GPU access\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Default advanced parameters enabled\n","Loaded Input images (number, width, length) = (294, 512, 1024)\n","Loaded Output images (number, width, length) = (294, 512, 1024)\n","Parameters initiated.\n","==================================================================\n","  294 raw images x    1 transformations   =   294 images\n","  294 images     x   10 patches per image =  2940 patches in total\n","==================================================================\n","Input data:\n","/content/: target='/content/gdrive/My Drive/cloud_colab/CARE (2D)/Train_300img/High', sources=['/content/gdrive/My Drive/cloud_colab/CARE (2D)/Train_300img/Low'], axes='CYX', pattern='*.tif*'\n","==================================================================\n","Transformations:\n","1 x Identity\n","==================================================================\n","Patch size:\n","64 x 64\n","==================================================================\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 294/294 [00:09<00:00, 31.95it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Creating 2D training dataset\n","number of training images:\t 2646\n","number of validation images:\t 294\n","image size (2D):\t\t (64, 64)\n","axes:\t\t\t\t SYXC\n","channels in / out:\t\t 1 / 1\n","42\n","Config(axes='YXC', n_channel_in=1, n_channel_out=1, n_dim=2, probabilistic=False, train_batch_size=64, train_checkpoint='weights_best.h5', train_checkpoint_epoch='weights_now.h5', train_checkpoint_last='weights_last.h5', train_epochs=1, train_learning_rate=0.0004, train_loss='mae', train_reduce_lr={'factor': 0.5, 'patience': 10, 'min_delta': 0}, train_steps_per_epoch=42, train_tensorboard=True, unet_input_shape=(None, None, 1), unet_kern_size=5, unet_last_activation='linear', unet_n_depth=3, unet_n_first=32, unet_residual=True)\n","Epoch 1/1\n","21/42 [==============>...............] - ETA: 5s - loss: 0.1848 - mse: 0.0596 - mae: 0.1848"],"name":"stdout"}]}]}